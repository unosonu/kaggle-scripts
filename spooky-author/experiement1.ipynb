{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use keras embedding to encode the dataset and see how it performs agains glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
       "1  id24541  If a fire wanted fanning, it could readily be ...\n",
       "2  id00134  And when they had broken down the frail door t...\n",
       "3  id27757  While I was thinking how I should possibly man...\n",
       "4  id04081  I am not sure to what limit his knowledge may ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(train.author.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train.text.values, y, \n",
    "                                                  stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, ..., 0, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#binarize the labels for neural net\n",
    "from keras.utils import np_utils\n",
    "ytrain_enc = np_utils.to_categorical(ytrain)\n",
    "yvalid_enc = np_utils.to_categorical(yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'Her hair was the brightest living gold, and despite the poverty of her clothing, seemed to set a crown of distinction on her head.',\n",
       "       '\"No,\" he said, \"oh, no a member of my family my niece, and a most accomplished woman.\"',\n",
       "       'The magistrate appeared at first perfectly incredulous, but as I continued he became more attentive and interested; I saw him sometimes shudder with horror; at others a lively surprise, unmingled with disbelief, was painted on his countenance.',\n",
       "       ...,\n",
       "       'The medical testimony spoke confidently of the virtuous character of the deceased.',\n",
       "       'When we arrived, after a little rest, he led me over the house and pointed out to me the rooms which my mother had inhabited.',\n",
       "       'Some were destroyed; the major part escaped by quick and well ordered movements; and danger made them careful.'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "xtrain_enc = [one_hot(d, vocab_size) for d in xtrain]\n",
    "xvalid_enc = [one_hot(d, vocab_size) for d in xvalid]\n",
    "#print(encoded_docs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_length = 300\n",
    "padded_docs_train = pad_sequences(xtrain_enc, maxlen=max_length, padding='post')\n",
    "padded_docs_valid = pad_sequences(xvalid_enc, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 90000)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 270003    \n",
      "=================================================================\n",
      "Total params: 3,270,003\n",
      "Trainable params: 3,270,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/5\n",
      "17621/17621 [==============================] - 12s 691us/step - loss: 0.0161 - acc: 0.9988 - val_loss: 0.6198 - val_acc: 0.7962\n",
      "Epoch 2/5\n",
      "17621/17621 [==============================] - 12s 689us/step - loss: 0.0096 - acc: 0.9997 - val_loss: 0.6523 - val_acc: 0.7967\n",
      "Epoch 3/5\n",
      "17621/17621 [==============================] - 12s 677us/step - loss: 0.0062 - acc: 0.9998 - val_loss: 0.6789 - val_acc: 0.7932\n",
      "Epoch 4/5\n",
      "17621/17621 [==============================] - 12s 689us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.7027 - val_acc: 0.7952\n",
      "Epoch 5/5\n",
      "17621/17621 [==============================] - 12s 681us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.7262 - val_acc: 0.7921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0908f2f210>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=5,  verbose=1,\n",
    "         validation_data=(padded_docs_valid,yvalid_enc))\n",
    "#model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=5,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 90000)             0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 300)               27000300  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 903       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 30,093,903\n",
      "Trainable params: 30,092,703\n",
      "Non-trainable params: 1,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# make another model for comparison\n",
    "# create a simple 3 layer sequential neural net\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(300, input_dim=300, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/5\n",
      "17621/17621 [==============================] - 75s 4ms/step - loss: 1.2875 - val_loss: 1.1930\n",
      "Epoch 2/5\n",
      "17621/17621 [==============================] - 74s 4ms/step - loss: 0.7970 - val_loss: 0.9204\n",
      "Epoch 3/5\n",
      "17621/17621 [==============================] - 74s 4ms/step - loss: 0.3205 - val_loss: 0.5748\n",
      "Epoch 4/5\n",
      "17621/17621 [==============================] - 74s 4ms/step - loss: 0.0965 - val_loss: 0.8387\n",
      "Epoch 5/5\n",
      "17621/17621 [==============================] - 74s 4ms/step - loss: 0.0300 - val_loss: 0.8989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08f41dd250>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=5,  verbose=1,\n",
    "         validation_data=(padded_docs_valid,yvalid_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_3 (Spatial (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1024)              103424    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 3)                 3075      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,316,499\n",
      "Trainable params: 4,316,499\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# trying lstm with early stopping to compare\n",
    "\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 159s 9ms/step - loss: 1.0898 - val_loss: 1.0877\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 172s 10ms/step - loss: 1.0896 - val_loss: 1.0891\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 142s 8ms/step - loss: 1.0888 - val_loss: 1.0876\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 121s 7ms/step - loss: 1.0897 - val_loss: 1.0881\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - 121s 7ms/step - loss: 1.0888 - val_loss: 1.0876\n",
      "Epoch 6/100\n",
      "17621/17621 [==============================] - 122s 7ms/step - loss: 1.0894 - val_loss: 1.0877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08ec2c0f90>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=512, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1024)              103424    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 3)                 3075      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,316,499\n",
      "Trainable params: 4,316,499\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# less dropout\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.3))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 123s 7ms/step - loss: 1.0894 - val_loss: 1.0887\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 123s 7ms/step - loss: 1.0887 - val_loss: 1.0876\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 122s 7ms/step - loss: 1.0880 - val_loss: 1.0879\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 122s 7ms/step - loss: 1.0881 - val_loss: 1.0877\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - 123s 7ms/step - loss: 1.0883 - val_loss: 1.0876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08ec320f90>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=512, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 3,160,703\n",
      "Trainable params: 3,160,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# simpler model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.3))\n",
    "\n",
    "# model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "# model.add(Dense(1024, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 119s 7ms/step - loss: 1.0896 - val_loss: 1.0887\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 118s 7ms/step - loss: 1.0889 - val_loss: 1.0880\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 116s 7ms/step - loss: 1.0880 - val_loss: 1.0877\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 116s 7ms/step - loss: 1.0878 - val_loss: 1.0880\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - 116s 7ms/step - loss: 1.0879 - val_loss: 1.0881\n",
      "Epoch 6/100\n",
      "17621/17621 [==============================] - 118s 7ms/step - loss: 1.0879 - val_loss: 1.0876\n",
      "Epoch 7/100\n",
      "17621/17621 [==============================] - 119s 7ms/step - loss: 1.0877 - val_loss: 1.0876\n",
      "Epoch 8/100\n",
      "17621/17621 [==============================] - 120s 7ms/step - loss: 1.0875 - val_loss: 1.0875\n",
      "Epoch 9/100\n",
      "17621/17621 [==============================] - 122s 7ms/step - loss: 1.0880 - val_loss: 1.0878\n",
      "Epoch 10/100\n",
      "17621/17621 [==============================] - 129s 7ms/step - loss: 1.0881 - val_loss: 1.0876\n",
      "Epoch 11/100\n",
      "17621/17621 [==============================] - 126s 7ms/step - loss: 1.0875 - val_loss: 1.0877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08f41bce50>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=512, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1024)              103424    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 3)                 3075      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 3,266,899\n",
      "Trainable params: 3,266,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# add one more layer of dense to teh simpler model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "#model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.3))\n",
    "model.add(LSTM(100))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Dense(1024, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 124s 7ms/step - loss: 1.0890 - val_loss: 1.0905\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 125s 7ms/step - loss: 1.0881 - val_loss: 1.0876\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 121s 7ms/step - loss: 1.0881 - val_loss: 1.0876\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 121s 7ms/step - loss: 1.0878 - val_loss: 1.0876\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - 125s 7ms/step - loss: 1.0876 - val_loss: 1.0879\n",
      "Epoch 6/100\n",
      "17621/17621 [==============================] - 121s 7ms/step - loss: 1.0875 - val_loss: 1.0882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08b6cac5d0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=512, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 90000)             0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 300)               27000300  \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 3)                 903       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 30,093,903\n",
      "Trainable params: 30,092,703\n",
      "Non-trainable params: 1,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "##lstms don't work so well here, why??\n",
    "## so back to dense layers - later try convolutions\n",
    "\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(300, input_dim=300, activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(300, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/5\n",
      "17621/17621 [==============================] - 75s 4ms/step - loss: 0.8608 - val_loss: 0.8716\n",
      "Epoch 2/5\n",
      "17621/17621 [==============================] - 73s 4ms/step - loss: 0.2487 - val_loss: 0.8537\n",
      "Epoch 3/5\n",
      "17621/17621 [==============================] - 73s 4ms/step - loss: 0.0700 - val_loss: 1.4063\n",
      "Epoch 4/5\n",
      "17621/17621 [==============================] - 73s 4ms/step - loss: 0.0326 - val_loss: 1.2074\n",
      "Epoch 5/5\n",
      "17621/17621 [==============================] - 73s 4ms/step - loss: 0.0255 - val_loss: 2.0335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08b35cff50>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=5,  verbose=1,\n",
    "         validation_data=(padded_docs_valid,yvalid_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 90000)             0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 300)               27000300  \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 3)                 903       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 30,185,403\n",
      "Trainable params: 30,183,603\n",
      "Non-trainable params: 1,800\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(300, input_dim=300, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 74s 4ms/step - loss: 0.0132 - val_loss: 1.1766\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 73s 4ms/step - loss: 0.0042 - val_loss: 1.2773\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 73s 4ms/step - loss: 0.0023 - val_loss: 1.2371\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 73s 4ms/step - loss: 0.0040 - val_loss: 1.3673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08b1f3ed90>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 19s 1ms/step - loss: 0.0764 - val_loss: 0.8002\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 18s 1ms/step - loss: 0.0410 - val_loss: 0.9359\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 18s 1ms/step - loss: 0.0253 - val_loss: 0.9545\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 18s 1ms/step - loss: 0.0163 - val_loss: 1.0312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08b49664d0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=512, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 42s 2ms/step - loss: 0.0160 - val_loss: 0.9846\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 42s 2ms/step - loss: 0.0112 - val_loss: 1.1052\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 41s 2ms/step - loss: 0.0058 - val_loss: 1.1030\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 41s 2ms/step - loss: 0.0046 - val_loss: 1.1845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08b1f3ec50>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=128, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 90000)             0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 300)               27000300  \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 3)                 903       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 30,093,903\n",
      "Trainable params: 30,092,703\n",
      "Non-trainable params: 1,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(300, input_dim=300, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 75s 4ms/step - loss: 1.3059 - val_loss: 1.0996\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 73s 4ms/step - loss: 1.0832 - val_loss: 0.9484\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 73s 4ms/step - loss: 0.5884 - val_loss: 0.6740\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 73s 4ms/step - loss: 0.2412 - val_loss: 0.5939\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - 73s 4ms/step - loss: 0.0781 - val_loss: 0.7839\n",
      "Epoch 6/100\n",
      "17621/17621 [==============================] - 73s 4ms/step - loss: 0.0329 - val_loss: 0.8665\n",
      "Epoch 7/100\n",
      "17621/17621 [==============================] - 73s 4ms/step - loss: 0.0212 - val_loss: 0.9947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08b43d7590>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 153s 9ms/step - loss: 0.1156 - val_loss: 1.0272\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 153s 9ms/step - loss: 0.1005 - val_loss: 1.0019\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 153s 9ms/step - loss: 0.0534 - val_loss: 0.8861\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 153s 9ms/step - loss: 0.0398 - val_loss: 1.0639\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - 153s 9ms/step - loss: 0.0349 - val_loss: 1.2094\n",
      "Epoch 6/100\n",
      "17621/17621 [==============================] - 153s 9ms/step - loss: 0.0376 - val_loss: 1.1328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08b14d68d0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=32, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## trying out cnn\n",
    "\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 300, 300)          270300    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 150, 300)          0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 45000)             0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 250)               11250250  \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 14,521,303\n",
      "Trainable params: 14,521,303\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Conv1D(filters=300, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 104s 6ms/step - loss: 0.7075 - acc: 0.6817 - val_loss: 0.5048 - val_acc: 0.7932\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 98s 6ms/step - loss: 0.3175 - acc: 0.8831 - val_loss: 0.5114 - val_acc: 0.7896\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 97s 5ms/step - loss: 0.1525 - acc: 0.9438 - val_loss: 0.6457 - val_acc: 0.7901\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 98s 6ms/step - loss: 0.0613 - acc: 0.9810 - val_loss: 0.9341 - val_acc: 0.7855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08b2cec1d0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 300, 300)          270300    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 150, 300)          0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 150, 300)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 150, 300)          1200      \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 45000)             0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 250)               11250250  \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 250)               1000      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 14,523,503\n",
      "Trainable params: 14,522,403\n",
      "Non-trainable params: 1,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Conv1D(filters=300, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 109s 6ms/step - loss: 0.9404 - acc: 0.5711 - val_loss: 0.9445 - val_acc: 0.4637\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 107s 6ms/step - loss: 0.3981 - acc: 0.8442 - val_loss: 0.5371 - val_acc: 0.7906\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 107s 6ms/step - loss: 0.2022 - acc: 0.9267 - val_loss: 0.5801 - val_acc: 0.7737\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 107s 6ms/step - loss: 0.1021 - acc: 0.9630 - val_loss: 0.6444 - val_acc: 0.7901\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - 107s 6ms/step - loss: 0.0623 - acc: 0.9784 - val_loss: 0.7826 - val_acc: 0.7778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08b0f9bf90>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_25 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 300, 8)            7208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 150, 8)            0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 150, 8)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 150, 8)            32        \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 250)               300250    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 250)               1000      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 3,309,243\n",
      "Trainable params: 3,308,727\n",
      "Non-trainable params: 516\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Conv1D(filters=8, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 21s 1ms/step - loss: 1.0777 - acc: 0.5215 - val_loss: 0.9330 - val_acc: 0.6129\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 19s 1ms/step - loss: 0.5483 - acc: 0.7762 - val_loss: 0.5948 - val_acc: 0.7661\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 20s 1ms/step - loss: 0.3854 - acc: 0.8511 - val_loss: 0.5341 - val_acc: 0.7773\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 20s 1ms/step - loss: 0.3051 - acc: 0.8839 - val_loss: 0.5730 - val_acc: 0.7799\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - 20s 1ms/step - loss: 0.2449 - acc: 0.9073 - val_loss: 0.6373 - val_acc: 0.7783\n",
      "Epoch 6/100\n",
      "17621/17621 [==============================] - 20s 1ms/step - loss: 0.2169 - acc: 0.9168 - val_loss: 0.6588 - val_acc: 0.7814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08a3a29ad0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_26 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 300, 8)            7208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 150, 8)            0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 150, 8)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 150, 8)            32        \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 250)               300250    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 250)               1000      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 3,309,243\n",
      "Trainable params: 3,308,727\n",
      "Non-trainable params: 516\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Conv1D(filters=8, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "nadam = optimizers.Nadam (lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 23s 1ms/step - loss: 0.8914 - acc: 0.5899 - val_loss: 0.9190 - val_acc: 0.6379\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 21s 1ms/step - loss: 0.5089 - acc: 0.7992 - val_loss: 0.5572 - val_acc: 0.7778\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 22s 1ms/step - loss: 0.3739 - acc: 0.8541 - val_loss: 0.6372 - val_acc: 0.7692\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 22s 1ms/step - loss: 0.3057 - acc: 0.8838 - val_loss: 0.6596 - val_acc: 0.7819\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - 22s 1ms/step - loss: 0.2686 - acc: 0.8959 - val_loss: 0.6323 - val_acc: 0.7799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08a29d7b50>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_27 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 300, 8)            7208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 150, 8)            0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 150, 8)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 150, 8)            32        \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 250)               300250    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 250)               1000      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 3,309,243\n",
      "Trainable params: 3,308,727\n",
      "Non-trainable params: 516\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#decreased learning rate\n",
    "from keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Conv1D(filters=8, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "nadam = optimizers.Nadam (lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 23s 1ms/step - loss: 1.0282 - acc: 0.5460 - val_loss: 0.9622 - val_acc: 0.5904\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 22s 1ms/step - loss: 0.5155 - acc: 0.7964 - val_loss: 0.5802 - val_acc: 0.7635\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 22s 1ms/step - loss: 0.3561 - acc: 0.8620 - val_loss: 0.5360 - val_acc: 0.7875\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 22s 1ms/step - loss: 0.2859 - acc: 0.8897 - val_loss: 0.5617 - val_acc: 0.7794\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - 22s 1ms/step - loss: 0.2300 - acc: 0.9135 - val_loss: 0.6056 - val_acc: 0.7901\n",
      "Epoch 6/100\n",
      "17621/17621 [==============================] - 22s 1ms/step - loss: 0.2016 - acc: 0.9237 - val_loss: 0.6354 - val_acc: 0.7896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08a1dd7e50>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_28 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 300, 8)            7208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 150, 8)            0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 250)               300250    \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 3,308,211\n",
      "Trainable params: 3,308,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Conv1D(filters=8, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "nadam = optimizers.Nadam (lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 23s 1ms/step - loss: 0.7142 - acc: 0.6779 - val_loss: 0.5149 - val_acc: 0.7916\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 21s 1ms/step - loss: 0.2950 - acc: 0.8912 - val_loss: 0.5387 - val_acc: 0.7896\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 21s 1ms/step - loss: 0.1175 - acc: 0.9598 - val_loss: 0.6866 - val_acc: 0.7896\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 21s 1ms/step - loss: 0.0406 - acc: 0.9881 - val_loss: 0.9310 - val_acc: 0.7804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08a3a4bf10>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_29 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 300, 8)            7208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 150, 8)            0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 250)               300250    \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 200)               50200     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 3)                 603       \n",
      "=================================================================\n",
      "Total params: 3,358,261\n",
      "Trainable params: 3,358,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# add one more layer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Conv1D(filters=8, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "nadam = optimizers.Nadam (lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 23s 1ms/step - loss: 0.7091 - acc: 0.6802 - val_loss: 0.5367 - val_acc: 0.7906\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 21s 1ms/step - loss: 0.2860 - acc: 0.8935 - val_loss: 0.5530 - val_acc: 0.8013\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 21s 1ms/step - loss: 0.1135 - acc: 0.9600 - val_loss: 0.7526 - val_acc: 0.7804\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 22s 1ms/step - loss: 0.0472 - acc: 0.9836 - val_loss: 1.0210 - val_acc: 0.7819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08a0f53a10>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_30 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 300, 250)          75250     \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 300, 8)            6008      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 150, 8)            0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 200)               240200    \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 3)                 603       \n",
      "=================================================================\n",
      "Total params: 3,322,061\n",
      "Trainable params: 3,322,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# change convolution layer to second layer\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Dense(250, activation='relu'))\n",
    "\n",
    "model.add(Conv1D(filters=8, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(200, activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "nadam = optimizers.Nadam (lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 31s 2ms/step - loss: 0.7564 - acc: 0.6501 - val_loss: 0.7046 - val_acc: 0.7135\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 29s 2ms/step - loss: 0.3657 - acc: 0.8602 - val_loss: 0.5976 - val_acc: 0.7620\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 29s 2ms/step - loss: 0.2151 - acc: 0.9187 - val_loss: 0.6215 - val_acc: 0.7835\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 29s 2ms/step - loss: 0.1247 - acc: 0.9561 - val_loss: 0.8164 - val_acc: 0.7870\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - 29s 2ms/step - loss: 0.0695 - acc: 0.9745 - val_loss: 1.0024 - val_acc: 0.7732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08a0c80690>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_32 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 300, 8)            7208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 150, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 150, 16)           400       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 75, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 250)               300250    \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 200)               50200     \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 3)                 603       \n",
      "=================================================================\n",
      "Total params: 3,358,661\n",
      "Trainable params: 3,358,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## add more convolutional layer\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Conv1D(filters=8, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Conv1D(filters=16, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "nadam = optimizers.Nadam (lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 24s 1ms/step - loss: 0.8040 - acc: 0.6194 - val_loss: 0.5769 - val_acc: 0.7697\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 22s 1ms/step - loss: 0.3582 - acc: 0.8628 - val_loss: 0.5707 - val_acc: 0.7804\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 21s 1ms/step - loss: 0.1485 - acc: 0.9470 - val_loss: 0.6926 - val_acc: 0.7753\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 22s 1ms/step - loss: 0.0668 - acc: 0.9771 - val_loss: 1.0711 - val_acc: 0.7492\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - 22s 1ms/step - loss: 0.0422 - acc: 0.9855 - val_loss: 1.3867 - val_acc: 0.7457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08b5c74650>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_33 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 300, 32)           28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 150, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 4800)              0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 250)               1200250   \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 4,229,835\n",
      "Trainable params: 4,229,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# keeping simpler model but increasing the number of filters to learn\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(250, activation='relu'))\n",
    "#model.add(Dense(200, activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "nadam = optimizers.Nadam (lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 27s 2ms/step - loss: 0.6978 - acc: 0.6859 - val_loss: 0.5246 - val_acc: 0.7722\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 25s 1ms/step - loss: 0.2997 - acc: 0.8871 - val_loss: 0.5388 - val_acc: 0.7916\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 25s 1ms/step - loss: 0.1167 - acc: 0.9612 - val_loss: 0.6537 - val_acc: 0.7937\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 25s 1ms/step - loss: 0.0310 - acc: 0.9920 - val_loss: 0.9063 - val_acc: 0.7891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08b5c6d050>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_34 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 300, 32)           28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 150, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 150, 16)           1552      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 75, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 250)               300250    \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 3,331,387\n",
      "Trainable params: 3,331,387\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Now add one more layer of convolution with half number of filters\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters=16, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(250, activation='relu'))\n",
    "#model.add(Dense(200, activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "nadam = optimizers.Nadam (lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 25s 1ms/step - loss: 0.7305 - acc: 0.6701 - val_loss: 0.5203 - val_acc: 0.7809\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 24s 1ms/step - loss: 0.3118 - acc: 0.8818 - val_loss: 0.5103 - val_acc: 0.7967\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 24s 1ms/step - loss: 0.1313 - acc: 0.9540 - val_loss: 0.6437 - val_acc: 0.7952\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 24s 1ms/step - loss: 0.0460 - acc: 0.9855 - val_loss: 0.9382 - val_acc: 0.7707\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - 24s 1ms/step - loss: 0.0144 - acc: 0.9965 - val_loss: 0.9863 - val_acc: 0.7998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08b5c746d0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_35 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 300, 32)           28832     \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 9600)              0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 250)               2400250   \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 5,429,835\n",
      "Trainable params: 5,429,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# KEEP simpler model but don't use max pooling\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(250, activation='relu'))\n",
    "#model.add(Dense(200, activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "nadam = optimizers.Nadam (lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 30s 2ms/step - loss: 0.7005 - acc: 0.6817 - val_loss: 0.5143 - val_acc: 0.7891\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 28s 2ms/step - loss: 0.3088 - acc: 0.8818 - val_loss: 0.5217 - val_acc: 0.7988\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 28s 2ms/step - loss: 0.1246 - acc: 0.9560 - val_loss: 0.6964 - val_acc: 0.7967\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 28s 2ms/step - loss: 0.0317 - acc: 0.9915 - val_loss: 0.9792 - val_acc: 0.7824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f089f867f90>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 300, 16)           14416     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 300, 32)           1568      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               2400250   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 5,416,987\n",
      "Trainable params: 5,416,987\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Now using two convolutional layers without using maxpooling\n",
    "\n",
    "# KEEP simpler model but don't use max pooling\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Conv1D(filters=16, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(250, activation='relu'))\n",
    "#model.add(Dense(200, activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "nadam = optimizers.Nadam (lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 40s 2ms/step - loss: 0.7099 - acc: 0.6809 - val_loss: 0.5224 - val_acc: 0.7835\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 29s 2ms/step - loss: 0.3263 - acc: 0.8751 - val_loss: 0.5226 - val_acc: 0.7957\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 28s 2ms/step - loss: 0.1602 - acc: 0.9420 - val_loss: 0.7958 - val_acc: 0.7702\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 29s 2ms/step - loss: 0.0665 - acc: 0.9771 - val_loss: 1.2759 - val_acc: 0.7375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f70317d9350>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 300, 300)          90300     \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 300, 64)           96064     \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 300, 32)           10272     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 9600)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 250)               2400250   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 5,597,639\n",
      "Trainable params: 5,597,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Dense(300, activation='relu'))\n",
    "\n",
    "model.add(Conv1D(filters=64, kernel_size=5, padding='same', activation='relu'))\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=5, padding='same', activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(250, activation='relu'))\n",
    "#model.add(Dense(200, activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "nadam = optimizers.Nadam (lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 56s 3ms/step - loss: 0.7868 - acc: 0.6270 - val_loss: 0.5483 - val_acc: 0.7707\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 55s 3ms/step - loss: 0.3864 - acc: 0.8505 - val_loss: 0.5379 - val_acc: 0.7768\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 55s 3ms/step - loss: 0.2505 - acc: 0.9080 - val_loss: 0.5791 - val_acc: 0.7773\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 55s 3ms/step - loss: 0.1757 - acc: 0.9345 - val_loss: 0.7585 - val_acc: 0.7702\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - 55s 3ms/step - loss: 0.1362 - acc: 0.9511 - val_loss: 0.8404 - val_acc: 0.7646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f702974d650>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 300, 32)           48032     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 9600)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 250)               2400250   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 5,449,035\n",
      "Trainable params: 5,449,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Using different kernel size\n",
    "# KEEP simpler model but don't use max pooling\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(250, activation='relu'))\n",
    "#model.add(Dense(200, activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "nadam = optimizers.Nadam (lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 31s 2ms/step - loss: 0.7136 - acc: 0.6813 - val_loss: 0.4958 - val_acc: 0.7937\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 31s 2ms/step - loss: 0.3169 - acc: 0.8772 - val_loss: 0.5449 - val_acc: 0.7926\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 31s 2ms/step - loss: 0.1331 - acc: 0.9541 - val_loss: 0.7122 - val_acc: 0.7870\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 31s 2ms/step - loss: 0.0343 - acc: 0.9895 - val_loss: 0.9415 - val_acc: 0.7932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7029866710>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 300, 32)           48032     \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 300, 64)           10304     \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 19200)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 250)               4800250   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 7,859,339\n",
      "Trainable params: 7,859,339\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Using different kernel size\n",
    "# KEEP simpler model but don't use max pooling\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(Conv1D(filters=64, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(250, activation='relu'))\n",
    "#model.add(Dense(200, activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "nadam = optimizers.Nadam (lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 42s 2ms/step - loss: 0.7186 - acc: 0.6761 - val_loss: 0.5270 - val_acc: 0.7809\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 41s 2ms/step - loss: 0.3400 - acc: 0.8706 - val_loss: 0.5205 - val_acc: 0.8029\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 41s 2ms/step - loss: 0.1880 - acc: 0.9310 - val_loss: 0.5984 - val_acc: 0.7906\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 41s 2ms/step - loss: 0.0964 - acc: 0.9646 - val_loss: 0.7995 - val_acc: 0.7906\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - 41s 2ms/step - loss: 0.0575 - acc: 0.9814 - val_loss: 1.1407 - val_acc: 0.7732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7029866750>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 300, 32)           48032     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 300, 400)          13200     \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 300, 64)           128064    \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 19200)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 250)               4800250   \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 753       \n",
      "=================================================================\n",
      "Total params: 7,990,299\n",
      "Trainable params: 7,990,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=5, padding='same', activation='relu'))\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Dense(400, activation='relu'))\n",
    "\n",
    "model.add(Conv1D(filters=64, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(250, activation='relu'))\n",
    "#model.add(Dense(200, activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "nadam = optimizers.Nadam (lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=nadam, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 75s 4ms/step - loss: 0.8777 - acc: 0.5714 - val_loss: 0.5831 - val_acc: 0.7671\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 74s 4ms/step - loss: 0.4025 - acc: 0.8422 - val_loss: 0.5307 - val_acc: 0.7783\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 74s 4ms/step - loss: 0.2125 - acc: 0.9220 - val_loss: 0.7077 - val_acc: 0.7768\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 74s 4ms/step - loss: 0.1101 - acc: 0.9606 - val_loss: 1.0982 - val_acc: 0.7288\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - 74s 4ms/step - loss: 0.0637 - acc: 0.9787 - val_loss: 1.0690 - val_acc: 0.7799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7031b84e50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 300, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 300, 32)           48032     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1024)              103424    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 3)                 3075      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 3,208,131\n",
      "Trainable params: 3,207,931\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#lstm with cnn\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 300, input_length=max_length))\n",
    "#model.add(Flatten())\n",
    "model.add(Conv1D(filters=32, kernel_size=5, padding='same', activation='relu'))\n",
    "\n",
    "model.add(LSTM(100))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 142s 8ms/step - loss: 1.0887 - val_loss: 1.0887\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 142s 8ms/step - loss: 1.0879 - val_loss: 5.3173\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 143s 8ms/step - loss: 1.0883 - val_loss: 9.5281\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 145s 8ms/step - loss: 1.0878 - val_loss: 1.5347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6ffc07c090>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 300, 300)     3000000     main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_12 (LSTM)                  (None, 100)          160400      embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_18 (Sequential)      (None, 9600)         48032       embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 9700)         0           lstm_12[0][0]                    \n",
      "                                                                 sequential_18[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1024)         9933824     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 3)            3075        dense_21[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 13,145,331\n",
      "Trainable params: 13,145,331\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Create a functional api for shared features from cnn and lstm\n",
    "\n",
    "#lstm with cnn\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "# Headline input: meant to receive sequences of 100 integers, between 1 and 10000.\n",
    "# Note that we can name any layer by passing it a \"name\" argument.\n",
    "main_input = Input(shape=(300,), dtype='int32', name='main_input')\n",
    "\n",
    "#question_input = Input(shape=(100,), dtype='int32')\n",
    "#embedded_question = Embedding(input_dim=10000, output_dim=256, input_length=100)(question_input)\n",
    "#encoded_question = LSTM(256)(embedded_question)\n",
    "\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 512-dimensional vectors.\n",
    "#x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)\n",
    "\n",
    "# A LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "#lstm_out = LSTM(32)(x)\n",
    "# vocab_size = 10000, maximum_length = 300\n",
    "x = Embedding(vocab_size, 300, input_length=max_length)(main_input)\n",
    "#model.add(Flatten())\n",
    "lstm_encoding = LSTM(100)(x)\n",
    "\n",
    "\n",
    "cnn_mod = Sequential()\n",
    "cnn_mod.add(Conv1D(filters=32, kernel_size=5, padding='same', activation='relu', input_shape=(300,300)))\n",
    "cnn_mod.add(Flatten())\n",
    "cnn_encoding = cnn_mod(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "merged = concatenate([lstm_encoding, cnn_encoding])\n",
    "\n",
    "#batch_normalized = BatchNormalization()(merged)\n",
    "\n",
    "\n",
    "\n",
    "hidden1 = Dense(1024, activation='relu')(merged)\n",
    "\n",
    "#hidden2 = Dense(3)(hidden1)\n",
    "output = Dense(3, activation = 'softmax')(hidden1)\n",
    "\n",
    "\n",
    "model = Model(inputs = main_input, outputs = output)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 263s 15ms/step - loss: 0.7126 - val_loss: 0.5137\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 261s 15ms/step - loss: 0.3072 - val_loss: 0.5431\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 262s 15ms/step - loss: 0.1026 - val_loss: 0.7131\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 268s 15ms/step - loss: 0.0260 - val_loss: 0.9948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6ffc28a5d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(padded_docs_train, y=ytrain_enc, batch_size=64, epochs=100, \n",
    "          verbose=1, validation_data=(padded_docs_valid, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "926"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "#del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##How to run multiple times and average the results\n",
    "##How to use cross validation\n",
    "##How to do model stacking\n",
    "##How to use abhishek's model stacking\n",
    "##be able to create a cnn layer and lstm together from input and then pass it to a dense layer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
